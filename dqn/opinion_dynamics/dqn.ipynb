{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys\n",
    "\n",
    "def get_dir_n_levels_up(path, n):\n",
    "    # Go up n levels from the given path\n",
    "    for _ in range(n):\n",
    "        path = os.path.dirname(path)\n",
    "    return path\n",
    "\n",
    "\n",
    "proj_root = get_dir_n_levels_up(os.path.abspath(\"__file__\"), 2)\n",
    "sys.path.append(proj_root)\n",
    "\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "from typing import Dict\n",
    "import logging\n",
    "\n",
    "from liftoff import parse_opts\n",
    "\n",
    "from opinion_dqn import AgentDQN\n",
    "from utils import my_logging\n",
    "from utils.experiment import seed_everything, create_path_to_experiment_folder, build_environment\n",
    "from utils.generic import convert_namespace_to_dict\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax in last layer because it scales with N instead of 2^N where N is the nr of agents\n",
    "\n",
    "# might need to do policy gradient\n",
    "\n",
    "# next step: Q iteration with action representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env = build_environment()\n",
    "train_env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-09 22:26:01,973 - opinion_agent_dqn - INFO - 3382193612.py:21 - Starting experiment: 2025Feb09-222523_configs_estimator.args_.lin_hidden_out_size=32\n",
      "2025-02-09 22:26:01,974 - opinion_agent_dqn - INFO - opinion_dqn.py:222 - Loaded configuration settings.\n",
      "2025-02-09 22:26:03,191 - opinion_agent_dqn - INFO - opinion_dqn.py:281 - Initialized newtworks and optimizer.\n",
      "2025-02-09 22:26:03,192 - opinion_agent_dqn - INFO - 3382193612.py:48 - Initialized agent with models: OpinionNet(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (predict_A_b_c): Linear(in_features=32, out_features=18, bias=True)\n",
      ")\n",
      "2025-02-09 22:26:03,192 - opinion_agent_dqn - INFO - opinion_dqn.py:464 - Starting training session at: 0\n",
      "2025-02-09 22:26:03,192 - opinion_agent_dqn - INFO - opinion_dqn.py:505 - Starting training epoch at t = 0\n",
      "2025-02-09 22:28:36,393 - opinion_agent_dqn - INFO - opinion_dqn.py:642 - TRAINING STATS | Frames seen: 200000 | Episode: 5610 | Max reward: -15.591267984316241 | Avg reward: -22.659765993329312 | Avg frames (episode): 35.64705882352941 | Avg max Q: -0.6824321962339712 | Epsilon: 0.2278 | Train epoch time: 0:02:33.168970\n",
      "2025-02-09 22:28:36,394 - opinion_agent_dqn - INFO - opinion_dqn.py:724 - Starting validation epoch at t = 200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\opinion_dqn.py:806: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(s, dtype=torch.float32), epsilon=self.validation_epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-09 22:29:23,952 - opinion_agent_dqn - INFO - opinion_dqn.py:822 - VALIDATION STATS | Max reward: -23.19952324072193 | Avg reward: -23.203239310665236 | Avg frames (episode): 38.0 | Avg max Q: -0.6860038215977795 | Validation epoch time: 0:00:47.539961\n",
      "2025-02-09 22:29:23,952 - opinion_agent_dqn - INFO - opinion_dqn.py:310 - Saving checkpoint at t = 200000 ...\n",
      "2025-02-09 22:29:24,862 - opinion_agent_dqn - INFO - opinion_dqn.py:314 - Checkpoint saved at t = 200000\n",
      "2025-02-09 22:29:24,862 - opinion_agent_dqn - INFO - opinion_dqn.py:490 - Epoch 0 completed in 0:03:21.670542\n",
      "2025-02-09 22:29:24,864 - opinion_agent_dqn - INFO - opinion_dqn.py:491 - \n",
      "\n",
      "2025-02-09 22:29:24,864 - opinion_agent_dqn - INFO - opinion_dqn.py:505 - Starting training epoch at t = 200000\n",
      "2025-02-09 22:31:59,627 - opinion_agent_dqn - INFO - opinion_dqn.py:642 - TRAINING STATS | Frames seen: 400000 | Episode: 11053 | Max reward: -21.696735465068684 | Avg reward: -22.693724133273868 | Avg frames (episode): 36.745544736358625 | Avg max Q: -0.6886446845541648 | Epsilon: 0.01 | Train epoch time: 0:02:34.721136\n",
      "2025-02-09 22:31:59,627 - opinion_agent_dqn - INFO - opinion_dqn.py:724 - Starting validation epoch at t = 400000\n",
      "2025-02-09 22:32:49,564 - opinion_agent_dqn - INFO - opinion_dqn.py:822 - VALIDATION STATS | Max reward: -22.268710388952393 | Avg reward: -22.271104957460405 | Avg frames (episode): 36.0 | Avg max Q: -0.6810669634061378 | Validation epoch time: 0:00:49.919359\n",
      "2025-02-09 22:32:49,565 - opinion_agent_dqn - INFO - opinion_dqn.py:310 - Saving checkpoint at t = 400000 ...\n",
      "2025-02-09 22:32:50,562 - opinion_agent_dqn - INFO - opinion_dqn.py:314 - Checkpoint saved at t = 400000\n",
      "2025-02-09 22:32:50,562 - opinion_agent_dqn - INFO - opinion_dqn.py:490 - Epoch 1 completed in 0:03:25.698323\n",
      "2025-02-09 22:32:50,562 - opinion_agent_dqn - INFO - opinion_dqn.py:491 - \n",
      "\n",
      "2025-02-09 22:32:50,563 - opinion_agent_dqn - INFO - opinion_dqn.py:505 - Starting training epoch at t = 400000\n",
      "2025-02-09 22:35:27,596 - opinion_agent_dqn - INFO - opinion_dqn.py:642 - TRAINING STATS | Frames seen: 600000 | Episode: 16719 | Max reward: -21.66126529888515 | Avg reward: -21.913075636139894 | Avg frames (episode): 35.30003529827039 | Avg max Q: -0.6804072677237677 | Epsilon: 0.01 | Train epoch time: 0:02:36.994799\n",
      "2025-02-09 22:35:27,597 - opinion_agent_dqn - INFO - opinion_dqn.py:724 - Starting validation epoch at t = 600000\n",
      "2025-02-09 22:36:15,072 - opinion_agent_dqn - INFO - opinion_dqn.py:822 - VALIDATION STATS | Max reward: -21.67850024943674 | Avg reward: -21.68223055389232 | Avg frames (episode): 35.0 | Avg max Q: -0.6836579837458804 | Validation epoch time: 0:00:47.456252\n",
      "2025-02-09 22:36:15,072 - opinion_agent_dqn - INFO - opinion_dqn.py:310 - Saving checkpoint at t = 600000 ...\n",
      "2025-02-09 22:36:15,989 - opinion_agent_dqn - INFO - opinion_dqn.py:314 - Checkpoint saved at t = 600000\n",
      "2025-02-09 22:36:15,990 - opinion_agent_dqn - INFO - opinion_dqn.py:490 - Epoch 2 completed in 0:03:25.427230\n",
      "2025-02-09 22:36:15,990 - opinion_agent_dqn - INFO - opinion_dqn.py:491 - \n",
      "\n",
      "2025-02-09 22:36:15,990 - opinion_agent_dqn - INFO - opinion_dqn.py:505 - Starting training epoch at t = 600000\n",
      "2025-02-09 22:38:52,234 - opinion_agent_dqn - INFO - opinion_dqn.py:642 - TRAINING STATS | Frames seen: 800000 | Episode: 22574 | Max reward: -21.13688528998662 | Avg reward: -21.335027911462866 | Avg frames (episode): 34.15781383432963 | Avg max Q: -0.6961567832263508 | Epsilon: 0.01 | Train epoch time: 0:02:36.202451\n",
      "2025-02-09 22:38:52,234 - opinion_agent_dqn - INFO - opinion_dqn.py:724 - Starting validation epoch at t = 800000\n",
      "2025-02-09 22:39:41,308 - opinion_agent_dqn - INFO - opinion_dqn.py:822 - VALIDATION STATS | Max reward: -21.160553185456877 | Avg reward: -21.16284172742665 | Avg frames (episode): 34.0 | Avg max Q: -0.7005979851130831 | Validation epoch time: 0:00:49.055417\n",
      "2025-02-09 22:39:41,308 - opinion_agent_dqn - INFO - opinion_dqn.py:310 - Saving checkpoint at t = 800000 ...\n",
      "2025-02-09 22:39:42,216 - opinion_agent_dqn - INFO - opinion_dqn.py:314 - Checkpoint saved at t = 800000\n",
      "2025-02-09 22:39:42,217 - opinion_agent_dqn - INFO - opinion_dqn.py:490 - Epoch 3 completed in 0:03:26.227012\n",
      "2025-02-09 22:39:42,217 - opinion_agent_dqn - INFO - opinion_dqn.py:491 - \n",
      "\n",
      "2025-02-09 22:39:42,217 - opinion_agent_dqn - INFO - opinion_dqn.py:505 - Starting training epoch at t = 800000\n",
      "2025-02-09 22:42:09,347 - opinion_agent_dqn - INFO - opinion_dqn.py:642 - TRAINING STATS | Frames seen: 1000000 | Episode: 28605 | Max reward: -20.666353066945483 | Avg reward: -20.83846724298731 | Avg frames (episode): 33.160835682308075 | Avg max Q: -0.7157204879259 | Epsilon: 0.01 | Train epoch time: 0:02:27.089464\n",
      "2025-02-09 22:42:09,348 - opinion_agent_dqn - INFO - opinion_dqn.py:724 - Starting validation epoch at t = 1000000\n",
      "2025-02-09 22:42:54,628 - opinion_agent_dqn - INFO - opinion_dqn.py:822 - VALIDATION STATS | Max reward: -20.66413500652978 | Avg reward: -20.667997647257412 | Avg frames (episode): 33.0 | Avg max Q: -0.721975950456835 | Validation epoch time: 0:00:45.262485\n",
      "2025-02-09 22:42:54,628 - opinion_agent_dqn - INFO - opinion_dqn.py:310 - Saving checkpoint at t = 1000000 ...\n",
      "2025-02-09 22:42:55,501 - opinion_agent_dqn - INFO - opinion_dqn.py:314 - Checkpoint saved at t = 1000000\n",
      "2025-02-09 22:42:55,502 - opinion_agent_dqn - INFO - opinion_dqn.py:490 - Epoch 4 completed in 0:03:13.285168\n",
      "2025-02-09 22:42:55,503 - opinion_agent_dqn - INFO - opinion_dqn.py:491 - \n",
      "\n",
      "2025-02-09 22:42:55,503 - opinion_agent_dqn - INFO - opinion_dqn.py:505 - Starting training epoch at t = 1000000\n",
      "2025-02-09 22:45:20,429 - opinion_agent_dqn - INFO - opinion_dqn.py:642 - TRAINING STATS | Frames seen: 1200000 | Episode: 34813 | Max reward: -20.277223752240744 | Avg reward: -20.3954770104027 | Avg frames (episode): 32.216978092783506 | Avg max Q: -0.7342549156553241 | Epsilon: 0.01 | Train epoch time: 0:02:24.887239\n",
      "2025-02-09 22:45:20,430 - opinion_agent_dqn - INFO - opinion_dqn.py:724 - Starting validation epoch at t = 1200000\n",
      "2025-02-09 22:46:06,129 - opinion_agent_dqn - INFO - opinion_dqn.py:822 - VALIDATION STATS | Max reward: -20.29781755308096 | Avg reward: -20.300452347485503 | Avg frames (episode): 32.0 | Avg max Q: -0.7450181265780378 | Validation epoch time: 0:00:45.681162\n",
      "2025-02-09 22:46:06,130 - opinion_agent_dqn - INFO - opinion_dqn.py:310 - Saving checkpoint at t = 1200000 ...\n",
      "2025-02-09 22:46:07,121 - opinion_agent_dqn - INFO - opinion_dqn.py:314 - Checkpoint saved at t = 1200000\n",
      "2025-02-09 22:46:07,122 - opinion_agent_dqn - INFO - opinion_dqn.py:490 - Epoch 5 completed in 0:03:11.618824\n",
      "2025-02-09 22:46:07,122 - opinion_agent_dqn - INFO - opinion_dqn.py:491 - \n",
      "\n",
      "2025-02-09 22:46:07,122 - opinion_agent_dqn - INFO - opinion_dqn.py:505 - Starting training epoch at t = 1200000\n",
      "2025-02-09 22:48:31,028 - opinion_agent_dqn - INFO - opinion_dqn.py:642 - TRAINING STATS | Frames seen: 1400000 | Episode: 41063 | Max reward: -20.242295307789384 | Avg reward: -20.296957632936287 | Avg frames (episode): 32.0 | Avg max Q: -0.7539668157865734 | Epsilon: 0.01 | Train epoch time: 0:02:23.865477\n",
      "2025-02-09 22:48:31,028 - opinion_agent_dqn - INFO - opinion_dqn.py:724 - Starting validation epoch at t = 1400000\n",
      "2025-02-09 22:49:16,700 - opinion_agent_dqn - INFO - opinion_dqn.py:822 - VALIDATION STATS | Max reward: -20.26466429525401 | Avg reward: -20.268242973353345 | Avg frames (episode): 32.0 | Avg max Q: -0.7632459374511744 | Validation epoch time: 0:00:45.654182\n",
      "2025-02-09 22:49:16,700 - opinion_agent_dqn - INFO - opinion_dqn.py:310 - Saving checkpoint at t = 1400000 ...\n",
      "2025-02-09 22:49:17,587 - opinion_agent_dqn - INFO - opinion_dqn.py:314 - Checkpoint saved at t = 1400000\n",
      "2025-02-09 22:49:17,588 - opinion_agent_dqn - INFO - opinion_dqn.py:490 - Epoch 6 completed in 0:03:10.466433\n",
      "2025-02-09 22:49:17,588 - opinion_agent_dqn - INFO - opinion_dqn.py:491 - \n",
      "\n",
      "2025-02-09 22:49:17,589 - opinion_agent_dqn - INFO - opinion_dqn.py:505 - Starting training epoch at t = 1400000\n",
      "2025-02-09 22:51:42,960 - opinion_agent_dqn - INFO - opinion_dqn.py:642 - TRAINING STATS | Frames seen: 1600000 | Episode: 47313 | Max reward: -20.176259265380647 | Avg reward: -20.250378316498278 | Avg frames (episode): 32.0 | Avg max Q: -0.7639183009277923 | Epsilon: 0.01 | Train epoch time: 0:02:25.332158\n",
      "2025-02-09 22:51:42,961 - opinion_agent_dqn - INFO - opinion_dqn.py:724 - Starting validation epoch at t = 1600000\n",
      "2025-02-09 22:52:28,488 - opinion_agent_dqn - INFO - opinion_dqn.py:822 - VALIDATION STATS | Max reward: -20.204671711800987 | Avg reward: -20.206585839663305 | Avg frames (episode): 32.0 | Avg max Q: -0.7668440420097425 | Validation epoch time: 0:00:45.510219\n",
      "2025-02-09 22:52:28,489 - opinion_agent_dqn - INFO - opinion_dqn.py:310 - Saving checkpoint at t = 1600000 ...\n",
      "2025-02-09 22:52:29,356 - opinion_agent_dqn - INFO - opinion_dqn.py:314 - Checkpoint saved at t = 1600000\n",
      "2025-02-09 22:52:29,356 - opinion_agent_dqn - INFO - opinion_dqn.py:490 - Epoch 7 completed in 0:03:11.766262\n",
      "2025-02-09 22:52:29,357 - opinion_agent_dqn - INFO - opinion_dqn.py:491 - \n",
      "\n",
      "2025-02-09 22:52:29,357 - opinion_agent_dqn - INFO - opinion_dqn.py:505 - Starting training epoch at t = 1600000\n",
      "2025-02-09 22:54:53,596 - opinion_agent_dqn - INFO - opinion_dqn.py:642 - TRAINING STATS | Frames seen: 1800000 | Episode: 53563 | Max reward: -20.12620117329994 | Avg reward: -20.17648419028651 | Avg frames (episode): 32.0 | Avg max Q: -0.770602421360895 | Epsilon: 0.01 | Train epoch time: 0:02:24.201008\n",
      "2025-02-09 22:54:53,596 - opinion_agent_dqn - INFO - opinion_dqn.py:724 - Starting validation epoch at t = 1800000\n",
      "2025-02-09 22:55:39,045 - opinion_agent_dqn - INFO - opinion_dqn.py:822 - VALIDATION STATS | Max reward: -20.150029427332083 | Avg reward: -20.151501466408 | Avg frames (episode): 32.0 | Avg max Q: -0.7747196379019771 | Validation epoch time: 0:00:45.430969\n",
      "2025-02-09 22:55:39,046 - opinion_agent_dqn - INFO - opinion_dqn.py:310 - Saving checkpoint at t = 1800000 ...\n",
      "2025-02-09 22:55:40,032 - opinion_agent_dqn - INFO - opinion_dqn.py:314 - Checkpoint saved at t = 1800000\n",
      "2025-02-09 22:55:40,032 - opinion_agent_dqn - INFO - opinion_dqn.py:490 - Epoch 8 completed in 0:03:10.675076\n",
      "2025-02-09 22:55:40,033 - opinion_agent_dqn - INFO - opinion_dqn.py:491 - \n",
      "\n",
      "2025-02-09 22:55:40,033 - opinion_agent_dqn - INFO - opinion_dqn.py:505 - Starting training epoch at t = 1800000\n",
      "2025-02-09 22:58:05,634 - opinion_agent_dqn - INFO - opinion_dqn.py:642 - TRAINING STATS | Frames seen: 2000000 | Episode: 59722 | Max reward: -20.120517873560683 | Avg reward: -20.880910282542793 | Avg frames (episode): 32.47410293878877 | Avg max Q: -0.776937059732372 | Epsilon: 0.01 | Train epoch time: 0:02:25.562183\n",
      "2025-02-09 22:58:05,635 - opinion_agent_dqn - INFO - opinion_dqn.py:724 - Starting validation epoch at t = 2000000\n",
      "2025-02-09 22:58:51,085 - opinion_agent_dqn - INFO - opinion_dqn.py:822 - VALIDATION STATS | Max reward: -20.38138486732185 | Avg reward: -20.384620872427675 | Avg frames (episode): 32.0 | Avg max Q: -0.798202728134704 | Validation epoch time: 0:00:45.432941\n",
      "2025-02-09 22:58:51,086 - opinion_agent_dqn - INFO - opinion_dqn.py:310 - Saving checkpoint at t = 2000000 ...\n",
      "2025-02-09 22:58:51,977 - opinion_agent_dqn - INFO - opinion_dqn.py:314 - Checkpoint saved at t = 2000000\n",
      "2025-02-09 22:58:51,977 - opinion_agent_dqn - INFO - opinion_dqn.py:490 - Epoch 9 completed in 0:03:11.943849\n",
      "2025-02-09 22:58:51,978 - opinion_agent_dqn - INFO - opinion_dqn.py:491 - \n",
      "\n",
      "2025-02-09 22:58:51,978 - opinion_agent_dqn - INFO - opinion_dqn.py:493 - Ended training session after 10 epochs at t = 2000000\n",
      "2025-02-09 22:58:51,979 - opinion_agent_dqn - INFO - 3382193612.py:54 - Finished training experiment: 2025Feb09-222523_configs_estimator.args_.lin_hidden_out_size=32, run_id: 0\n"
     ]
    }
   ],
   "source": [
    "experiment_yaml = \"2025Feb10-225340_configs\"\n",
    "yaml_path = Path(\n",
    "    r\"D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\"\n",
    ") / experiment_yaml / \"0000_estimator.args_.lin_hidden_out_size_32\" / \"0\" / \"cfg.yaml\"\n",
    "\n",
    "\n",
    "with open(yaml_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "seed = int(os.path.basename(config[\"out_dir\"]))\n",
    "\n",
    "seed_everything(seed)\n",
    "\n",
    "logs_file = os.path.join(config[\"out_dir\"], \"experiment_log.log\")\n",
    "\n",
    "logger = my_logging.setup_logger(\n",
    "    name=config[\"experiment\"],\n",
    "    # log_file=logs_file,\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "logger.info(f\"Starting experiment: {config['full_title']}\")\n",
    "\n",
    "### Setup output and loading paths ###\n",
    "\n",
    "path_previous_experiments_outputs = None\n",
    "if \"restart_training_timestamp\" in config:\n",
    "    path_previous_experiments_outputs = create_path_to_experiment_folder(\n",
    "        config,\n",
    "        config[\"out_dir\"],\n",
    "        config[\"restart_training_timestamp\"],\n",
    "    )\n",
    "\n",
    "experiment_agent = AgentDQN(\n",
    "    experiment_output_folder=config[\"out_dir\"],\n",
    "    experiment_name=config[\"experiment\"],\n",
    "    resume_training_path=path_previous_experiments_outputs,\n",
    "    save_checkpoints=True,\n",
    "    logger=logger,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f'Initialized agent with models: {experiment_agent.policy_model}'\n",
    ")\n",
    "\n",
    "experiment_agent.train(train_epochs=config[\"epochs_to_train\"])\n",
    "\n",
    "logger.info(\n",
    "    f'Finished training experiment: {config[\"full_title\"]}, run_id: {config[\"run_id\"]}'\n",
    ")\n",
    "\n",
    "my_logging.cleanup_file_handlers(experiment_logger=logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    "\n",
    "# nr_betas = 2\n",
    "# nr_agents = 3\n",
    "# batch_size = 2\n",
    "\n",
    "# # Create a sample A_b_c_net matrix with unique integer values for visualization\n",
    "# A_b_c_net = torch.tensor([\n",
    "#     [[10, 11, 12, 13, 14, 15, 16], \n",
    "#      [20, 21, 22, 23, 24, 25, 26]],  # Batch 1\n",
    "#     [[30, 31, 32, 33, 34, 35, 36], \n",
    "#      [40, 41, 42, 43, 44, 45, 46]]   # Batch 2\n",
    "# ], dtype=torch.float32)\n",
    "\n",
    "# # Extract components\n",
    "# c = A_b_c_net[:, :, 0]  # Free term (first column)\n",
    "# A_diag = torch.exp(A_b_c_net[:, :, 1 : nr_agents + 1])  # Positive definite diagonal (next `nr_agents` columns)\n",
    "# b = A_b_c_net[:, :, nr_agents + 1 :]  # Bias term (remaining columns)\n",
    "\n",
    "# # Print extracted values for visualization\n",
    "# print(nr_betas * (2 * nr_agents + 1))\n",
    "# print(\"A_b_c_net:\\n\", A_b_c_net)\n",
    "# print(\"\\nExtracted c (free term):\\n\", c)\n",
    "# print(\"\\nExtracted A_diag (exponentiated for positivity):\\n\", A_diag)\n",
    "# print(\"\\nExtracted b (bias term):\\n\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd_rl_algos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
