{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chainsword\\AppData\\Local\\Temp\\ipykernel_57552\\1225861293.py:18: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "def get_dir_n_levels_up(path, n):\n",
    "    # Go up n levels from the given path\n",
    "    for _ in range(n):\n",
    "        path = os.path.dirname(path)\n",
    "    return path\n",
    "\n",
    "proj_root = get_dir_n_levels_up(os.path.abspath(\"__file__\"), 4)\n",
    "sys.path.append(proj_root)\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import glob\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dqn.opinion_dynamics.opinion_dqn import AgentDQN\n",
    "from dqn.opinion_dynamics.utils.my_logging import setup_logger\n",
    "from dqn.opinion_dynamics.utils.experiment import build_environment, process_experiment\n",
    "\n",
    "from dynamic_programming.opinion_dynamics.common.viz import plot_opinions_over_time, visualize_policy_from_env\n",
    "\n",
    "\n",
    "def instantiate_agent(exp_subdir_path: str) -> AgentDQN:\n",
    "    \"\"\"\n",
    "    Instantiate an AgentDQN using the configuration stored in a YAML file \n",
    "    in the provided experiment subdirectory. The agent is created with the \n",
    "    given training and validation environments and loads its previous state.\n",
    "    \n",
    "    Args:\n",
    "        exp_subdir_path (str): Path to the experiment subdirectory containing the config YAML and checkpoint files.\n",
    "     \n",
    "    Returns:\n",
    "        AgentDQN: An instance of AgentDQN initialized using the experiment configuration and saved state.\n",
    "    \"\"\"\n",
    "    # Assume the YAML configuration is stored as 'config.yaml' in the experiment folder.\n",
    "    config_path = os.path.join(exp_subdir_path, \"cfg.yaml\")\n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Config file not found at {config_path}\")\n",
    "    \n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Instantiate the agent.\n",
    "    # The resume_training_path is set to the experiment folder so that the agent loads saved weights/stats.\n",
    "    agent = AgentDQN(\n",
    "        resume_training_path=exp_subdir_path,\n",
    "        experiment_name=config[\"experiment\"],\n",
    "        config=config,\n",
    "        save_checkpoints=False,  # you can set this as needed\n",
    "        logger=setup_logger(\"dqn\", level=logging.ERROR)\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "def run_policy_agent(env, agent, max_steps=10):\n",
    "    \"\"\"\n",
    "    Run the simulation using the agent’s policy (exploitation only).\n",
    "    \n",
    "    Args:\n",
    "        env: The environment (which must have a reset and step method).\n",
    "        agent: An already-trained AgentDQN instance.\n",
    "        max_steps: Maximum number of steps to run.\n",
    "        \n",
    "    Returns:\n",
    "        opinions_over_time: Array of opinions (states) over time.\n",
    "        time_points: Array of time stamps.\n",
    "        rewards_over_time: Array of rewards collected at each step.\n",
    "        actions_over_time: Array of actions taken at each step.\n",
    "    \"\"\"\n",
    "    time_points = []\n",
    "    rewards_over_time = []\n",
    "    actions_over_time = []  # New: record the actions used.\n",
    "    opinions_over_time = []\n",
    "    \n",
    "    current_time = 0.0\n",
    "    # Reset environment\n",
    "    state, _ = env.reset()\n",
    "    opinions_over_time.append(state.copy())\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        # Convert state to a batched tensor (batch size = 1)\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        # Use the agent in exploitation mode (epsilon=0, random_action=False)\n",
    "        # The agent.select_action returns (action, beta_idx, q_value)\n",
    "        action, _, _, _ = agent.select_action(state_tensor, epsilon=0.0, random_action=False)\n",
    "        # action is returned as a NumPy array with shape (1, n_agents)\n",
    "        action = np.squeeze(action)  # Now action has shape (n_agents,)\n",
    "        actions_over_time.append(action.copy())\n",
    "        \n",
    "        # Apply the action in the environment.\n",
    "        next_state, reward, done, truncated, _ = env.step(action, env.tau)\n",
    "        opinions_over_time.append(next_state.copy())\n",
    "        rewards_over_time.append(reward)\n",
    "        time_points.append(current_time)\n",
    "        \n",
    "        current_time += env.tau\n",
    "        state = next_state\n",
    "        \n",
    "        if done or truncated:\n",
    "            print(f\"Simulation ended at step {step}: done={done}, truncated={truncated}\")\n",
    "            break\n",
    "\n",
    "    return (np.array(opinions_over_time),\n",
    "            np.array(time_points),\n",
    "            np.array(rewards_over_time),\n",
    "            np.array(actions_over_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chainsword\\AppData\\Local\\Temp\\ipykernel_57552\\3450333892.py:13: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  == metadata_df.groupby(\"sub_experiment_path\")[\"frame_stamp\"].transform(max)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment number 1 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0000_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0000_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 2 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0000_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0000_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 3 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0001_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.1\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0001_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.1\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 4 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0001_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.1\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0001_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.1\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 5 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0002_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.3\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0002_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.3\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 6 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0002_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.3\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0002_optim.args_.eps_1e-06__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.3\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 7 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0003_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0003_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 8 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0003_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0003_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 9 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0004_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.1\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0004_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.1\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 10 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0004_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.1\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0004_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.1\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 11 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0005_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.3\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0005_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.3\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 12 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0005_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.3\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0005_optim.args_.eps_1e-06__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.3\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 13 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0006_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0006_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 14 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0006_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0006_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 15 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0007_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.1\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0007_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.1\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 16 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0007_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.1\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0007_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.1\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 17 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0008_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.3\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0008_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.3\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 18 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0008_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.3\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0008_optim.args_.eps_1e-05__optim.args_.lr_1e-05__agent_params.args_.action_w_noise_amplitude_0.3\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 19 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0009_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0009_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 20 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0009_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0009_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 21 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0010_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.1\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0010_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.1\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 22 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0010_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.1\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0010_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.1\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 23 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0011_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.3\\0\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0011_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.3\\0: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n",
      "Running experiment number 24 out of 24: D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0011_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.3\\1\n",
      "❌ Failed to run experiment at D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\\2025Apr29-212301_configs\\0011_optim.args_.eps_1e-05__optim.args_.lr_0.0001__agent_params.args_.action_w_noise_amplitude_0.3\\1: OpinionNet.__init__() got an unexpected keyword argument 'lin_hidden_out_size'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Step 3: Plot\u001b[39;00m\n\u001b[32m     54\u001b[39m df = pd.DataFrame(all_runs)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m     56\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mnoise_amplitude\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mnoise_amplitude\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m     58\u001b[39m g = sns.FacetGrid(\n\u001b[32m     59\u001b[39m     df,\n\u001b[32m     60\u001b[39m     row=\u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     sharey=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     65\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chainsword\\anaconda3\\envs\\phd_rl_algos\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4088\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4089\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4090\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4091\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4092\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chainsword\\anaconda3\\envs\\phd_rl_algos\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'seed'"
     ]
    }
   ],
   "source": [
    "EXP_DIR = r\"2025Apr29-212301_configs\"\n",
    "EXPERIMENTS_ROOT_DIR = r\"D:\\Work\\repos\\RL\\phd-rl-algos\\dqn\\opinion_dynamics\\experiments\\results\"\n",
    "EXPERIMENTS_ROOT = os.path.join(EXPERIMENTS_ROOT_DIR, EXP_DIR)\n",
    "GAMMA = 0.9\n",
    "\n",
    "# Step 1: Get metadata (seed, noise, etc.) from your existing util\n",
    "metadata_df = process_experiment(EXPERIMENTS_ROOT)\n",
    "# For each sub_experiment_path, select only the ones where the epoch_type is \"training\", and select only the row with the maximum frame_stamp\n",
    "metadata_df = metadata_df[\n",
    "    (metadata_df[\"epoch_type\"] == \"training\")\n",
    "    & (\n",
    "        metadata_df[\"frame_stamp\"]\n",
    "        == metadata_df.groupby(\"sub_experiment_path\")[\"frame_stamp\"].transform(max)\n",
    "    )\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Step 2: Run agents and gather reward trajectories\n",
    "all_runs = []\n",
    "\n",
    "for i, row in metadata_df.iterrows():\n",
    "    print(\n",
    "        f\"Running experiment number {i+1} out of {len(metadata_df)}: {row['sub_experiment_path']}\"\n",
    "    )\n",
    "    subdir = row[\"sub_experiment_path\"]\n",
    "    noise = float(row.get(\"sub_exp_cfg_agent_params.args_.action_w_noise_amplitude\", 0))\n",
    "    seed = row.get(\"seed\", \"unknown\")\n",
    "\n",
    "    try:\n",
    "        env = build_environment()\n",
    "        agent = instantiate_agent(subdir)\n",
    "        opinions, times, rewards, actions = run_policy_agent(env, agent, max_steps=30)\n",
    "\n",
    "        discounted_return = sum((GAMMA**t) * r for t, r in enumerate(rewards))\n",
    "\n",
    "        for step, (t, opinion_vec) in enumerate(zip(times, opinions)):\n",
    "            for agent_id, opinion_val in enumerate(opinion_vec):\n",
    "                all_runs.append(\n",
    "                    {\n",
    "                        \"noise_amplitude\": noise,\n",
    "                        \"seed\": seed,\n",
    "                        \"time\": t,\n",
    "                        \"step\": step,\n",
    "                        \"agent_id\": agent_id,\n",
    "                        \"opinion\": opinion_val,\n",
    "                        \"experiment\": os.path.basename(subdir),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to run experiment at {subdir}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Step 3: Plot\n",
    "df = pd.DataFrame(all_runs)\n",
    "df[\"seed\"] = df[\"seed\"].astype(str)\n",
    "df[\"noise_amplitude\"] = df[\"noise_amplitude\"].astype(str)\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    df,\n",
    "    row=\"seed\",\n",
    "    col=\"noise_amplitude\",\n",
    "    hue=\"agent_id\",\n",
    "    margin_titles=True,\n",
    "    sharey=True,\n",
    ")\n",
    "g.map_dataframe(sns.lineplot, x=\"step\", y=\"opinion\")\n",
    "g.set_axis_labels(\"Time\", \"Opinion\")\n",
    "g.set_titles(row_template=\"Seed: {row_name}\", col_template=\"Noise: {col_name}\")\n",
    "g.add_legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_amplitude</th>\n",
       "      <th>seed</th>\n",
       "      <th>time</th>\n",
       "      <th>step</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>opinion</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.385480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.872200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.967567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.950695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.888052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2124 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     noise_amplitude seed  time  step  agent_id   opinion experiment\n",
       "0                0.0    0   0.0     0         0  0.300000          0\n",
       "1                0.0    0   0.0     0         1  0.200000          0\n",
       "2                0.0    0   0.0     0         2  0.100000          0\n",
       "3                0.0    0   0.0     0         3  0.000000          0\n",
       "4                0.0    0   0.1     1         0  0.385480          0\n",
       "...              ...  ...   ...   ...       ...       ...        ...\n",
       "2119             0.3    1   1.6    16         3  0.872200          1\n",
       "2120             0.3    1   1.7    17         0  0.974237          1\n",
       "2121             0.3    1   1.7    17         1  0.967567          1\n",
       "2122             0.3    1   1.7    17         2  0.950695          1\n",
       "2123             0.3    1   1.7    17         3  0.888052          1\n",
       "\n",
       "[2124 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd_rl_algos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
